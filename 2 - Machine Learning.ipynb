{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51b99750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries and moduels \n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression as c_lm\n",
    "from sklearn.neighbors import KNeighborsClassifier as c_knn\n",
    "from sklearn.tree import DecisionTreeClassifier as c_dt\n",
    "from sklearn.ensemble import RandomForestClassifier as c_rf, GradientBoostingClassifier as c_gbf\n",
    "from sklearn.svm import SVC as c_svm\n",
    "from sklearn.neural_network import MLPClassifier as c_mlp\n",
    "\n",
    "# Hyperparam tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model evaluation\n",
    "from ml_pipeline.model_evaluation import evaluate_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b8e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data, perform SAME (match random state) train/test split\n",
    "path = \"data/dirty_credit_data (1).csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Split target from data\n",
    "target = 'Defaulted'\n",
    "\n",
    "# Drop records w/o target (can't train if no target)\n",
    "data.dropna(subset = [target], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Separate target from the rest of the data\n",
    "cols = list(data.columns)\n",
    "cols.remove(target)\n",
    "\n",
    "# Define dependent and independent variables\n",
    "y = data[target]\n",
    "X = data[cols]\n",
    "\n",
    "# Immediately train test split\n",
    "# ! THE RANDOM SEED MUST MATCH WHAT YOU DID DURING DATA PREP!!!\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54bb2735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING (OneHotEncode): column 'employment_status' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category '#Other').\n",
      "WARNING (OneHotEncode): column 'loan_purpose' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category 'medical').\n",
      "WARNING (OneHotEncode): column 'married' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category 'married').\n",
      "WARNING (IngestAndPrepare): age has values greater than the maximum training value: 75.2. You will be extrapolating outside of the training data range.\n",
      "WARNING (IngestAndPrepare): wtd_ave_debt_interest has values less than the minimum training value: 0.0279. You will be extrapolating outside of the training data range.\n",
      "WARNING (OneHotEncode): column 'employment_status' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category '#Other').\n",
      "WARNING (OneHotEncode): column 'loan_purpose' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category 'medical').\n",
      "WARNING (OneHotEncode): column 'married' has new categories in transform data that were not seen during fit: {nan}. These will be encoded as all zeros (same as the dropped category 'married').\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>income</th>\n",
       "      <th>wtd_ave_debt_interest</th>\n",
       "      <th>ln(total_debt)</th>\n",
       "      <th>ln(loan_value)</th>\n",
       "      <th>employment_status_full-time</th>\n",
       "      <th>employment_status_part-time</th>\n",
       "      <th>employment_status_unemployed</th>\n",
       "      <th>employment_status_full-tme</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_purpose_credit_card</th>\n",
       "      <th>loan_purpose_auto</th>\n",
       "      <th>loan_purpose_business</th>\n",
       "      <th>loan_purpose_mortgage</th>\n",
       "      <th>married_single</th>\n",
       "      <th>prior_default_n</th>\n",
       "      <th>education_level_2</th>\n",
       "      <th>education_level_3</th>\n",
       "      <th>education_level_1</th>\n",
       "      <th>education_level_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9069</th>\n",
       "      <td>35.9</td>\n",
       "      <td>690.0</td>\n",
       "      <td>105072.0</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>10.476245</td>\n",
       "      <td>10.476273</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>36.6</td>\n",
       "      <td>643.0</td>\n",
       "      <td>47074.0</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>9.019664</td>\n",
       "      <td>9.028219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>46.3</td>\n",
       "      <td>740.0</td>\n",
       "      <td>54489.0</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>8.470102</td>\n",
       "      <td>8.494129</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>54.7</td>\n",
       "      <td>737.0</td>\n",
       "      <td>131456.0</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>11.850140</td>\n",
       "      <td>11.850176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>44.8</td>\n",
       "      <td>633.0</td>\n",
       "      <td>67539.0</td>\n",
       "      <td>0.1557</td>\n",
       "      <td>8.916506</td>\n",
       "      <td>8.913819</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  credit_score    income  wtd_ave_debt_interest  ln(total_debt)  \\\n",
       "9069  35.9         690.0  105072.0                 0.1457       10.476245   \n",
       "2603  36.6         643.0   47074.0                 0.1337        9.019664   \n",
       "7738  46.3         740.0   54489.0                 0.1041        8.470102   \n",
       "1579  54.7         737.0  131456.0                 0.1269       11.850140   \n",
       "5058  44.8         633.0   67539.0                 0.1557        8.916506   \n",
       "\n",
       "      ln(loan_value)  employment_status_full-time  \\\n",
       "9069       10.476273                            0   \n",
       "2603        9.028219                            1   \n",
       "7738        8.494129                            1   \n",
       "1579       11.850176                            1   \n",
       "5058        8.913819                            0   \n",
       "\n",
       "      employment_status_part-time  employment_status_unemployed  \\\n",
       "9069                            1                             0   \n",
       "2603                            0                             0   \n",
       "7738                            0                             0   \n",
       "1579                            0                             0   \n",
       "5058                            1                             0   \n",
       "\n",
       "      employment_status_full-tme  ...  loan_purpose_credit_card  \\\n",
       "9069                           0  ...                         1   \n",
       "2603                           0  ...                         1   \n",
       "7738                           0  ...                         0   \n",
       "1579                           0  ...                         0   \n",
       "5058                           0  ...                         1   \n",
       "\n",
       "      loan_purpose_auto  loan_purpose_business  loan_purpose_mortgage  \\\n",
       "9069                  0                      0                      0   \n",
       "2603                  0                      0                      0   \n",
       "7738                  0                      0                      0   \n",
       "1579                  0                      0                      1   \n",
       "5058                  0                      0                      0   \n",
       "\n",
       "      married_single  prior_default_n  education_level_2  education_level_3  \\\n",
       "9069               1                1                  1                  0   \n",
       "2603               0                1                  0                  0   \n",
       "7738               1                1                  1                  0   \n",
       "1579               1                1                  1                  0   \n",
       "5058               0                0                  1                  0   \n",
       "\n",
       "      education_level_1  education_level_0  \n",
       "9069                  0                  0  \n",
       "2603                  1                  0  \n",
       "7738                  0                  0  \n",
       "1579                  0                  0  \n",
       "5058                  0                  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pickle and transform data\n",
    "with open(\"./pickles/data_pipeline.pickle\", 'rb') as handle:\n",
    "    pipe = pickle.load(handle)\n",
    "    x_tr = pipe.transform(x_tr)\n",
    "    x_te = pipe.transform(x_te)\n",
    "\n",
    "x_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9a58eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m lm_model = c_lm()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Train the model \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mlm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Generate Predictions\u001b[39;00m\n\u001b[32m     11\u001b[39m lm_tr = lm_model.predict(x_tr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1191\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1189\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m   1201\u001b[39m check_classification_targets(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2917\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2918\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     out = X, y\n\u001b[32m   2922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1314\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1309\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1312\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1333\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\5375winiecc\\Desktop\\4420\\4420_ML_Pipeline\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Model Two\n",
    "# Linear Regression\n",
    "# Instantiate    \n",
    "    # No Hyperparameters for this model\n",
    "lm_model = c_lm()\n",
    "\n",
    "# Train the model \n",
    "lm_model.fit(x_tr, y_tr)\n",
    "\n",
    "# Generate Predictions\n",
    "lm_tr = lm_model.predict(x_tr)\n",
    "lm_te = lm_model.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb21046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics, blindcm, traincm, testcm = evaluate_classification(y_tr, lm_tr, y_te, lm_te)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 \n",
    "# Grid Search and GBF Model \n",
    "model = gbf()\n",
    "\n",
    "# Define parameter ranges\n",
    "param_grid = {\n",
    "              'n_estimators': [100, 150, 200, 250],\n",
    "              'max_depth': [2,3,4,6],\n",
    "              'max_features': ['sqrt', 'log2', None]\n",
    "             }\n",
    "\n",
    "# Create GridSearchCV object\n",
    "folds = 5\n",
    "grid_search = GridSearchCV(model, param_grid, cv=folds)\n",
    "\n",
    "# Fit the model to the data\n",
    "grid_search.fit(x_tr, y_tr)\n",
    "\n",
    "# Print the best parameters\n",
    "best = grid_search.best_params_\n",
    "print(\"Best parameters: \", best)\n",
    "\n",
    "# Generate Predictions\n",
    "grid_tr = grid_search.predict(x_tr)\n",
    "grid_te = grid_search.predict(x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics, blindcm, traincm, testcm = evaluate_classification(y_tr, gbf_tr, y_te, gbf_te)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1113266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set confusion matrix\n",
    "traincm.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cebe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincm.confusion_matrix_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20749d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set confusion matrix\n",
    "testcm.confusion_matrix_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No clue what this does but needed for gbf \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "lbl = list(gbf_model.feature_names_in_)\n",
    "imp = list(gbf_model.feature_importances_)\n",
    "impdf = pd.DataFrame({'variable':lbl,'importance':imp})\n",
    "impdf.sort_values('importance', ascending=False, inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize = (12,12))\n",
    "sns.barplot(x=impdf['importance'], y=impdf['variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize the model \n",
    "X = pd.concat([x_tr, x_te], axis = 0, ignore_index = True)\n",
    "y = pd.concat([y_tr, y_te], axis = 0, ignore_index = True)\n",
    "\n",
    "# We use the same exact hyperparameters from tuning\n",
    "gbf_model = c_gbf(n_estimators = 50, max_depth = 2)\n",
    "\n",
    "# Train the model \n",
    "gbf_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle and save the model\n",
    "with open(\"./pickles/supply_chain_classifier.pickle\", 'wb') as handle:\n",
    "    pickle.dump(gbf_model, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4420-ml-pipeline-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
